{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fab27a",
   "metadata": {},
   "source": [
    "# 画像変換テスト\n",
    "\n",
    "このノートブックでは、以下の画像変換を段階的に適用し、各変換の前後を比較表示します：\n",
    "\n",
    "1. **明るさ・コントラスト調整**\n",
    "   - ガンマ補正 (Gamma Correction)\n",
    "   - 線形スケーリング (Brightness/Contrast)\n",
    "\n",
    "2. **ヒストグラム均等化／CLAHE**\n",
    "   - グローバル均等化\n",
    "   - CLAHE (適応的ヒストグラム均等化)\n",
    "\n",
    "3. **ノイズ除去・輪郭強調**\n",
    "   - 非局所平均フィルタ\n",
    "   - アンシャープマスク（シャープ化）\n",
    "\n",
    "4. **クロップ＆リサイズ**\n",
    "   - 中心部分のクロップ\n",
    "   - 推奨解像度へのリサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b80e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 日本語フォントの設定\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# 表示用関数\n",
    "def show_image_comparison(original, processed, title, subtitle=\"\"):\n",
    "    \"\"\"2つの画像を横並びで比較表示\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 元画像\n",
    "    axes[0].imshow(original, cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 処理後画像\n",
    "    axes[1].imshow(processed, cmap='gray')\n",
    "    axes[1].set_title('Processed')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"{title}\\n{subtitle}\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_histogram_comparison(original, processed, title):\n",
    "    \"\"\"ヒストグラムを比較表示\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # 元画像とヒストグラム\n",
    "    axes[0, 0].imshow(original, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].hist(original.ravel(), bins=256, range=[0, 256], color='blue', alpha=0.7)\n",
    "    axes[0, 1].set_title('Original Histogram')\n",
    "    axes[0, 1].set_xlabel('Pixel Value')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # 処理後画像とヒストグラム\n",
    "    axes[1, 0].imshow(processed, cmap='gray')\n",
    "    axes[1, 0].set_title('Processed Image')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].hist(processed.ravel(), bins=256, range=[0, 256], color='red', alpha=0.7)\n",
    "    axes[1, 1].set_title('Processed Histogram')\n",
    "    axes[1, 1].set_xlabel('Pixel Value')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"ライブラリとユーティリティ関数の準備完了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像パスの設定（テスト用画像を指定）\n",
    "# 例: OK画像の1つを使用\n",
    "image_path = r\"input\\背景カットなし\\sample\\OK\\OK3.png\"\n",
    "\n",
    "# 日本語パス対応のための画像読み込み関数\n",
    "def read_image_japanese_path(image_path, color_flag=cv2.IMREAD_GRAYSCALE):\n",
    "    \"\"\"日本語パスに対応した画像読み込み関数\"\"\"\n",
    "    try:\n",
    "        # NumPyを使用してバイナリファイルを読み込み\n",
    "        with open(image_path, 'rb') as f:\n",
    "            binary_data = f.read()\n",
    "        \n",
    "        # バイナリデータからNumPy配列に変換\n",
    "        img_array = np.frombuffer(binary_data, dtype=np.uint8)\n",
    "        \n",
    "        # OpenCVでデコード\n",
    "        img = cv2.imdecode(img_array, color_flag)\n",
    "        \n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"画像読み込みエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "# 画像が存在するかチェック\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"画像パス: {image_path}\")\n",
    "    print(\"画像が見つかりました！\")\n",
    "    \n",
    "    # 画像読み込み（グレースケール）- 日本語パス対応\n",
    "    original_img = read_image_japanese_path(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if original_img is not None:\n",
    "        print(f\"画像サイズ: {original_img.shape}\")\n",
    "        \n",
    "        # 元画像を表示\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(original_img, cmap='gray')\n",
    "        plt.title(f\"Original Image: {os.path.basename(image_path)}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # 基本統計情報\n",
    "        print(f\"最小値: {original_img.min()}\")\n",
    "        print(f\"最大値: {original_img.max()}\")\n",
    "        print(f\"平均値: {original_img.mean():.2f}\")\n",
    "        print(f\"標準偏差: {original_img.std():.2f}\")\n",
    "    else:\n",
    "        print(\"画像の読み込みに失敗しました\")\n",
    "        print(\"ファイル形式またはパスに問題がある可能性があります\")\n",
    "else:\n",
    "    print(f\"画像が見つかりません: {image_path}\")\n",
    "    print(\"パスを確認してください\")\n",
    "    \n",
    "    # 代替画像パスを提案\n",
    "    print(\"\\n=== 利用可能な画像ファイル ===\")\n",
    "    try:\n",
    "        sample_dir = r\"input\\背景カットなし\\sample\"\n",
    "        for category in os.listdir(sample_dir):\n",
    "            category_path = os.path.join(sample_dir, category)\n",
    "            if os.path.isdir(category_path):\n",
    "                print(f\"\\n{category}:\")\n",
    "                for file in os.listdir(category_path):\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        print(f\"  - {os.path.join(category_path, file)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ディレクトリ読み込みエラー: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a518fb",
   "metadata": {},
   "source": [
    "## 1. 明るさ・コントラスト調整\n",
    "\n",
    "### 1-1. ガンマ補正 (Gamma Correction)\n",
    "ガンマ補正は、画像の明るさを非線形的に調整する手法です。\n",
    "- γ < 1: 暗い部分を明るくする（全体的に明るくなる）\n",
    "- γ > 1: 明るい部分を暗くする（全体的に暗くなる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ガンマ補正の実装\n",
    "def gamma_correction(image, gamma):\n",
    "    \"\"\"ガンマ補正を適用\"\"\"\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# 異なるガンマ値でテスト\n",
    "gamma_values = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "# 現在の画像をコピー\n",
    "current_img = original_img.copy()\n",
    "\n",
    "print(\"ガンマ補正の比較:\")\n",
    "for gamma in gamma_values:\n",
    "    img_gamma = gamma_correction(current_img, gamma)\n",
    "    \n",
    "    # 比較表示\n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        img_gamma, \n",
    "        f\"Gamma Correction (γ = {gamma})\",\n",
    "        f\"暗部補正: {'強' if gamma < 1 else '弱' if gamma > 1 else 'なし'}\"\n",
    "    )\n",
    "    \n",
    "    # ヒストグラム比較\n",
    "    show_histogram_comparison(\n",
    "        current_img,\n",
    "        img_gamma,\n",
    "        f\"Histogram Comparison - Gamma = {gamma}\"\n",
    "    )\n",
    "\n",
    "# 最適なガンマ値を選択（例：1.5）\n",
    "optimal_gamma = 1.5\n",
    "img_gamma = gamma_correction(current_img, optimal_gamma)\n",
    "\n",
    "print(f\"\\n最適なガンマ値 {optimal_gamma} を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebc053",
   "metadata": {},
   "source": [
    "### 1-2. 線形スケーリング (Brightness/Contrast)\n",
    "線形変換： output = α × input + β\n",
    "- α (alpha): コントラスト係数（1.0 = 変化なし、>1.0 = 高コントラスト）\n",
    "- β (beta): 明るさオフセット（0 = 変化なし、>0 = 明るく、<0 = 暗く）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形スケーリングのテスト\n",
    "def linear_scaling(image, alpha, beta):\n",
    "    \"\"\"線形スケーリングを適用\"\"\"\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "# 異なるパラメータでテスト\n",
    "alpha_values = [0.8, 1.0, 1.2, 1.5]  # コントラスト\n",
    "beta_values = [-20, 0, 20, 40]        # 明るさ\n",
    "\n",
    "print(\"線形スケーリングの比較:\")\n",
    "\n",
    "# コントラストの効果を確認\n",
    "current_img = img_gamma.copy()\n",
    "for alpha in alpha_values:\n",
    "    img_contrast = linear_scaling(current_img, alpha, 0)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        img_contrast, \n",
    "        f\"Contrast Adjustment (α = {alpha})\",\n",
    "        f\"コントラスト: {'低' if alpha < 1 else '高' if alpha > 1 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# 明るさの効果を確認\n",
    "for beta in beta_values:\n",
    "    img_brightness = linear_scaling(current_img, 1.0, beta)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        img_brightness, \n",
    "        f\"Brightness Adjustment (β = {beta})\",\n",
    "        f\"明るさ: {'暗' if beta < 0 else '明' if beta > 0 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# 最適な値を組み合わせて適用\n",
    "optimal_alpha = 1.2  # コントラスト\n",
    "optimal_beta = 20    # 明るさ\n",
    "\n",
    "img_bc = linear_scaling(current_img, optimal_alpha, optimal_beta)\n",
    "\n",
    "# 最終結果を表示\n",
    "show_image_comparison(\n",
    "    current_img, \n",
    "    img_bc, \n",
    "    f\"Final Brightness & Contrast (α={optimal_alpha}, β={optimal_beta})\",\n",
    "    \"ガンマ補正 + 線形スケーリング\"\n",
    ")\n",
    "\n",
    "print(f\"\\n最適なパラメータ (α={optimal_alpha}, β={optimal_beta}) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fd932",
   "metadata": {},
   "source": [
    "## 2. ヒストグラム均等化／CLAHE\n",
    "\n",
    "### 2-1. グローバルヒストグラム均等化\n",
    "画像全体のヒストグラムを均等化し、コントラストを改善します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2672cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# グローバルヒストグラム均等化\n",
    "current_img = original_img.copy()\n",
    "\n",
    "# ヒストグラム均等化を適用\n",
    "hist_eq = cv2.equalizeHist(current_img)\n",
    "\n",
    "# 比較表示\n",
    "show_image_comparison(\n",
    "    current_img, \n",
    "    hist_eq, \n",
    "    \"Global Histogram Equalization\",\n",
    "    \"グローバルなコントラスト改善\"\n",
    ")\n",
    "\n",
    "# ヒストグラム比較\n",
    "show_histogram_comparison(\n",
    "    current_img,\n",
    "    hist_eq,\n",
    "    \"Global Histogram Equalization - Histogram Comparison\"\n",
    ")\n",
    "\n",
    "print(\"グローバルヒストグラム均等化を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09cfa0a",
   "metadata": {},
   "source": [
    "### 2-2. CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "適応的ヒストグラム均等化により、局所的なコントラストを改善しつつ、過度な増強を抑制します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef259667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE (適応的ヒストグラム均等化)\n",
    "# 異なるパラメータでテスト\n",
    "clip_limits = [1.0, 2.0, 3.0, 4.0]\n",
    "tile_sizes = [(4, 4), (8, 8), (16, 16)]\n",
    "\n",
    "print(\"CLAHE パラメータの比較:\")\n",
    "\n",
    "# Clip Limitの効果を確認\n",
    "current_img = original_img.copy()\n",
    "for clip_limit in clip_limits:\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))\n",
    "    clahe_eq = clahe.apply(current_img)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        clahe_eq, \n",
    "        f\"CLAHE (clipLimit={clip_limit})\",\n",
    "        f\"制限値: {'低' if clip_limit < 2 else '高' if clip_limit > 2 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# Tile Grid Sizeの効果を確認\n",
    "for tile_size in tile_sizes:\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=tile_size)\n",
    "    clahe_eq = clahe.apply(current_img)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        clahe_eq, \n",
    "        f\"CLAHE (tileGridSize={tile_size})\",\n",
    "        f\"タイルサイズ: {'小' if tile_size[0] < 8 else '大' if tile_size[0] > 8 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# 最適なパラメータを選択\n",
    "optimal_clip_limit = 2.0\n",
    "optimal_tile_size = (8, 8)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=optimal_clip_limit, tileGridSize=optimal_tile_size)\n",
    "clahe_eq = clahe.apply(current_img)\n",
    "\n",
    "# CLAHE vs グローバル均等化の比較\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(current_img, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(hist_eq, cmap='gray')\n",
    "axes[1].set_title('Global Histogram Equalization')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(clahe_eq, cmap='gray')\n",
    "axes[2].set_title('CLAHE')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(\"Histogram Equalization Methods Comparison\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n最適なCLAHEパラメータ (clipLimit={optimal_clip_limit}, tileGridSize={optimal_tile_size}) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8f1377",
   "metadata": {},
   "source": [
    "## 3. ノイズ除去・輪郭強調\n",
    "\n",
    "### 3-1. 非局所平均フィルタ (Non-Local Means Denoising)\n",
    "画像のディテールを保持しながらノイズを除去します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノイズ除去フィルタのテスト\n",
    "current_img = original_img.copy()\n",
    "\n",
    "# 異なるパラメータでテスト\n",
    "h_values = [10, 30, 50]  # ノイズ除去の強さ\n",
    "template_window_sizes = [5, 7, 9]  # テンプレートウィンドウサイズ\n",
    "\n",
    "print(\"ノイズ除去フィルタの比較:\")\n",
    "\n",
    "# h値の効果を確認\n",
    "for h in h_values:\n",
    "    denoised = cv2.fastNlMeansDenoising(current_img, None, h=h, templateWindowSize=7, searchWindowSize=21)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        denoised, \n",
    "        f\"Non-Local Means Denoising (h={h})\",\n",
    "        f\"ノイズ除去強度: {'弱' if h < 30 else '強' if h > 30 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# テンプレートウィンドウサイズの効果を確認\n",
    "for template_size in template_window_sizes:\n",
    "    denoised = cv2.fastNlMeansDenoising(current_img, None, h=30, templateWindowSize=template_size, searchWindowSize=21)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        denoised, \n",
    "        f\"Non-Local Means Denoising (templateWindowSize={template_size})\",\n",
    "        f\"テンプレートサイズ: {'小' if template_size < 7 else '大' if template_size > 7 else '標準'}\"\n",
    "    )\n",
    "\n",
    "# 最適なパラメータを選択\n",
    "optimal_h = 30\n",
    "optimal_template_size = 7\n",
    "optimal_search_size = 21\n",
    "\n",
    "denoised = cv2.fastNlMeansDenoising(\n",
    "    current_img, \n",
    "    None, \n",
    "    h=optimal_h, \n",
    "    templateWindowSize=optimal_template_size, \n",
    "    searchWindowSize=optimal_search_size\n",
    ")\n",
    "\n",
    "print(f\"\\n最適なノイズ除去パラメータ (h={optimal_h}, templateWindowSize={optimal_template_size}) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c9412",
   "metadata": {},
   "source": [
    "### 3-2. アンシャープマスク (Sharpening)\n",
    "エッジを強調してディテールを鮮明にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28258c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# アンシャープマスク（シャープ化）\n",
    "current_img = original_img.copy()\n",
    "\n",
    "# 異なるシャープ化カーネルをテスト\n",
    "kernels = {\n",
    "    \"Mild Sharpening\": np.array([[0, -1, 0],\n",
    "                                [-1, 5, -1],\n",
    "                                [0, -1, 0]]),\n",
    "    \n",
    "    \"Standard Sharpening\": np.array([[-1, -1, -1],\n",
    "                                    [-1, 9, -1],\n",
    "                                    [-1, -1, -1]]),\n",
    "    \n",
    "    \"Strong Sharpening\": np.array([[0, -1, 0],\n",
    "                                  [-1, 6, -1],\n",
    "                                  [0, -1, 0]]),\n",
    "    \n",
    "    \"Edge Enhancement\": np.array([[-1, -1, -1],\n",
    "                                 [-1, 8, -1],\n",
    "                                 [-1, -1, -1]]) / 8\n",
    "}\n",
    "\n",
    "print(\"シャープ化カーネルの比較:\")\n",
    "\n",
    "# 各カーネルの効果を確認\n",
    "sharpened_results = {}\n",
    "for kernel_name, kernel in kernels.items():\n",
    "    sharpened = cv2.filter2D(current_img, -1, kernel)\n",
    "    sharpened_results[kernel_name] = sharpened\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        sharpened, \n",
    "        f\"Sharpening: {kernel_name}\",\n",
    "        f\"エッジ強調度: {kernel_name.split()[0]}\"\n",
    "    )\n",
    "\n",
    "# 最適なカーネルを選択\n",
    "optimal_kernel_name = \"Mild Sharpening\"\n",
    "optimal_kernel = kernels[optimal_kernel_name]\n",
    "\n",
    "sharpened = cv2.filter2D(current_img, -1, optimal_kernel)\n",
    "\n",
    "# ノイズ除去 → シャープ化の効果を確認\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(clahe_eq, cmap='gray')\n",
    "axes[0].set_title('Before Denoising')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(denoised, cmap='gray')\n",
    "axes[1].set_title('After Denoising')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sharpened, cmap='gray')\n",
    "axes[2].set_title('After Sharpening')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(\"Denoising → Sharpening Process\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n最適なシャープ化カーネル ({optimal_kernel_name}) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e91d99",
   "metadata": {},
   "source": [
    "## 4. クロップ＆リサイズ\n",
    "\n",
    "### 4-1. 中心クロップ\n",
    "画像の中心部分を取り出して、背景ノイズを除去します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロップ＆リサイズ\n",
    "current_img = sharpened.copy()\n",
    "\n",
    "def center_crop(image, crop_size):\n",
    "    \"\"\"画像の中心部分をクロップ\"\"\"\n",
    "    h, w = image.shape\n",
    "    cx, cy = w // 2, h // 2\n",
    "    \n",
    "    # クロップサイズを画像サイズに合わせて調整\n",
    "    crop_h, crop_w = crop_size\n",
    "    crop_h = min(crop_h, h)\n",
    "    crop_w = min(crop_w, w)\n",
    "    \n",
    "    # クロップ領域を計算\n",
    "    y1 = max(0, cy - crop_h // 2)\n",
    "    y2 = min(h, cy + crop_h // 2)\n",
    "    x1 = max(0, cx - crop_w // 2)\n",
    "    x2 = min(w, cx + crop_w // 2)\n",
    "    \n",
    "    return image[y1:y2, x1:x2]\n",
    "\n",
    "# 元画像のサイズを確認\n",
    "h, w = current_img.shape\n",
    "print(f\"元画像サイズ: {w} x {h}\")\n",
    "\n",
    "# 異なるクロップサイズをテスト\n",
    "crop_sizes = [\n",
    "    (min(h, w) // 2, min(h, w) // 2),  # 小さなクロップ\n",
    "    (min(h, w) * 3 // 4, min(h, w) * 3 // 4),  # 中程度のクロップ\n",
    "    (min(h, w), min(h, w))  # 正方形クロップ\n",
    "]\n",
    "\n",
    "print(\"クロップサイズの比較:\")\n",
    "\n",
    "cropped_results = {}\n",
    "for i, crop_size in enumerate(crop_sizes):\n",
    "    cropped = center_crop(current_img, crop_size)\n",
    "    cropped_results[f\"Crop_{i+1}\"] = cropped\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        cropped, \n",
    "        f\"Center Crop ({crop_size[0]} x {crop_size[1]})\",\n",
    "        f\"クロップサイズ: {crop_size[0]} x {crop_size[1]}\"\n",
    "    )\n",
    "\n",
    "# 最適なクロップサイズを選択\n",
    "optimal_crop_size = crop_sizes[1]  # 中程度のクロップ\n",
    "cropped = center_crop(current_img, optimal_crop_size)\n",
    "\n",
    "print(f\"\\n最適なクロップサイズ ({optimal_crop_size[0]} x {optimal_crop_size[1]}) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c701c",
   "metadata": {},
   "source": [
    "### 4-2. リサイズ\n",
    "モデルの推奨解像度に合わせてリサイズします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リサイズ\n",
    "current_img = cropped.copy()\n",
    "\n",
    "# 異なるリサイズサイズをテスト\n",
    "resize_sizes = [\n",
    "    (256, 256),\n",
    "    (512, 512),\n",
    "    (768, 768),\n",
    "    (1024, 1024)\n",
    "]\n",
    "\n",
    "# 異なる補間方法をテスト\n",
    "interpolation_methods = {\n",
    "    \"INTER_NEAREST\": cv2.INTER_NEAREST,\n",
    "    \"INTER_LINEAR\": cv2.INTER_LINEAR,\n",
    "    \"INTER_CUBIC\": cv2.INTER_CUBIC,\n",
    "    \"INTER_AREA\": cv2.INTER_AREA,\n",
    "    \"INTER_LANCZOS4\": cv2.INTER_LANCZOS4\n",
    "}\n",
    "\n",
    "print(\"リサイズサイズの比較:\")\n",
    "\n",
    "# 各サイズの効果を確認\n",
    "for size in resize_sizes:\n",
    "    resized = cv2.resize(current_img, size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        resized, \n",
    "        f\"Resize to {size[0]} x {size[1]}\",\n",
    "        f\"解像度: {size[0]} x {size[1]}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n補間方法の比較:\")\n",
    "\n",
    "# 補間方法の効果を確認（512x512でテスト）\n",
    "target_size = (512, 512)\n",
    "for method_name, method in interpolation_methods.items():\n",
    "    resized = cv2.resize(current_img, target_size, interpolation=method)\n",
    "    \n",
    "    show_image_comparison(\n",
    "        current_img, \n",
    "        resized, \n",
    "        f\"Resize with {method_name}\",\n",
    "        f\"補間方法: {method_name}\"\n",
    "    )\n",
    "\n",
    "# 最適なパラメータを選択\n",
    "optimal_size = (512, 512)\n",
    "optimal_interpolation = cv2.INTER_AREA\n",
    "\n",
    "final_image = cv2.resize(current_img, optimal_size, interpolation=optimal_interpolation)\n",
    "\n",
    "print(f\"\\n最適なリサイズパラメータ (size={optimal_size}, interpolation=INTER_AREA) を適用しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f4fff",
   "metadata": {},
   "source": [
    "## 5. 最終結果の比較\n",
    "\n",
    "すべての変換処理を適用した結果を、元画像と比較して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終結果の比較表示\n",
    "def show_preprocessing_pipeline(original, steps_images, step_names, title=\"Image Preprocessing Pipeline\"):\n",
    "    \"\"\"前処理パイプラインの全段階を表示\"\"\"\n",
    "    num_steps = len(steps_images)\n",
    "    cols = min(4, num_steps + 1)  # 最大4列\n",
    "    rows = (num_steps + 1 + cols - 1) // cols  # 必要な行数\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))\n",
    "    axes = axes.flatten() if rows > 1 else [axes] if cols == 1 else axes\n",
    "    \n",
    "    # 元画像\n",
    "    axes[0].imshow(original, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # 各段階の結果\n",
    "    for i, (img, name) in enumerate(zip(steps_images, step_names)):\n",
    "        axes[i + 1].imshow(img, cmap='gray')\n",
    "        axes[i + 1].set_title(name)\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    # 使用しない軸を非表示\n",
    "    for i in range(num_steps + 1, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 処理段階の画像を収集\n",
    "preprocessing_steps = [\n",
    "    img_gamma,    # ガンマ補正\n",
    "    img_bc,       # 線形スケーリング\n",
    "    clahe_eq,     # CLAHE\n",
    "    denoised,     # ノイズ除去\n",
    "    sharpened,    # シャープ化\n",
    "    cropped,      # クロップ\n",
    "    final_image   # 最終リサイズ\n",
    "]\n",
    "\n",
    "step_names = [\n",
    "    \"1. Gamma Correction\",\n",
    "    \"2. Brightness & Contrast\",\n",
    "    \"3. CLAHE\",\n",
    "    \"4. Denoising\",\n",
    "    \"5. Sharpening\",\n",
    "    \"6. Cropping\",\n",
    "    \"7. Final Resize\"\n",
    "]\n",
    "\n",
    "# パイプライン全体の表示\n",
    "show_preprocessing_pipeline(\n",
    "    original_img, \n",
    "    preprocessing_steps, \n",
    "    step_names,\n",
    "    \"Complete Image Preprocessing Pipeline\"\n",
    ")\n",
    "\n",
    "# 元画像と最終結果の比較\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "axes[0].imshow(original_img, cmap='gray')\n",
    "axes[0].set_title(f'Original Image\\nSize: {original_img.shape}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(final_image, cmap='gray')\n",
    "axes[1].set_title(f'Processed Image\\nSize: {final_image.shape}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Before & After Preprocessing\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 処理前後の統計情報比較\n",
    "print(\"=== 処理前後の統計情報比較 ===\")\n",
    "print(f\"元画像 - サイズ: {original_img.shape}, 平均: {original_img.mean():.2f}, 標準偏差: {original_img.std():.2f}\")\n",
    "print(f\"最終画像 - サイズ: {final_image.shape}, 平均: {final_image.mean():.2f}, 標準偏差: {final_image.std():.2f}\")\n",
    "\n",
    "# 最終画像を保存\n",
    "output_path = \"preprocessed_image.png\"\n",
    "cv2.imwrite(output_path, final_image)\n",
    "print(f\"\\n処理済み画像を保存しました: {output_path}\")\n",
    "\n",
    "print(\"\\n=== 処理パイプライン完了 ===\")\n",
    "print(\"1. ガンマ補正 → 暗部を明るく調整\")\n",
    "print(\"2. 線形スケーリング → コントラストと明るさを調整\")\n",
    "print(\"3. CLAHE → 適応的ヒストグラム均等化\")\n",
    "print(\"4. ノイズ除去 → 非局所平均フィルタでノイズを除去\")\n",
    "print(\"5. シャープ化 → エッジを強調\")\n",
    "print(\"6. クロップ → 中心部分を抽出\")\n",
    "print(\"7. リサイズ → モデル推奨解像度に調整\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092c4ed",
   "metadata": {},
   "source": [
    "## 6. パラメータ調整用（オプション）\n",
    "\n",
    "このセクションでは、異なる画像に対してパラメータを簡単に調整できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaa70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ調整用関数\n",
    "def preprocess_image_with_params(image_path, \n",
    "                                gamma=1.5, \n",
    "                                alpha=1.2, \n",
    "                                beta=20,\n",
    "                                clip_limit=2.0,\n",
    "                                tile_size=(8, 8),\n",
    "                                denoise_h=30,\n",
    "                                template_size=7,\n",
    "                                sharpen_strength=\"mild\",\n",
    "                                crop_ratio=0.75,\n",
    "                                final_size=(512, 512)):\n",
    "    \"\"\"\n",
    "    指定されたパラメータで画像を前処理する関数\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: 画像のパス\n",
    "    - gamma: ガンマ補正値\n",
    "    - alpha: コントラスト係数\n",
    "    - beta: 明るさオフセット\n",
    "    - clip_limit: CLAHEのクリップ制限\n",
    "    - tile_size: CLAHEのタイルサイズ\n",
    "    - denoise_h: ノイズ除去の強さ\n",
    "    - template_size: ノイズ除去のテンプレートサイズ\n",
    "    - sharpen_strength: シャープ化の強さ (\"mild\", \"standard\", \"strong\")\n",
    "    - crop_ratio: クロップ比率\n",
    "    - final_size: 最終リサイズサイズ\n",
    "    \"\"\"\n",
    "    \n",
    "    # 画像読み込み（日本語パス対応）\n",
    "    img = read_image_japanese_path(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"画像の読み込みに失敗: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # 1. ガンマ補正\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, table)\n",
    "    \n",
    "    # 2. 線形スケーリング\n",
    "    img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # 3. CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "    img = clahe.apply(img)\n",
    "    \n",
    "    # 4. ノイズ除去\n",
    "    img = cv2.fastNlMeansDenoising(img, None, h=denoise_h, templateWindowSize=template_size, searchWindowSize=21)\n",
    "    \n",
    "    # 5. シャープ化\n",
    "    sharpen_kernels = {\n",
    "        \"mild\": np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
    "        \"standard\": np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]),\n",
    "        \"strong\": np.array([[0, -1, 0], [-1, 6, -1], [0, -1, 0]])\n",
    "    }\n",
    "    kernel = sharpen_kernels.get(sharpen_strength, sharpen_kernels[\"mild\"])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    \n",
    "    # 6. クロップ\n",
    "    h, w = img.shape\n",
    "    crop_size = int(min(h, w) * crop_ratio)\n",
    "    img = center_crop(img, (crop_size, crop_size))\n",
    "    \n",
    "    # 7. リサイズ\n",
    "    img = cv2.resize(img, final_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return img\n",
    "\n",
    "# 使用例：他の画像でテスト\n",
    "def test_different_images():\n",
    "    \"\"\"異なる画像でパラメータをテスト\"\"\"\n",
    "    \n",
    "    # テスト画像のパス（存在する場合）\n",
    "    test_images = [\n",
    "        r\"input\\背景カットなし\\sample\\OK\\OK2.png\",\n",
    "        r\"input\\背景カットなし\\sample\\削り節\\削り節1.png\",\n",
    "        r\"input\\背景カットなし\\sample\\欠け\\欠け1.png\",\n",
    "        r\"input\\背景カットなし\\sample\\汚れ\\汚れ1.png\"\n",
    "    ]\n",
    "    \n",
    "    for img_path in test_images:\n",
    "        if os.path.exists(img_path):\n",
    "            print(f\"\\n=== テスト画像: {os.path.basename(img_path)} ===\")\n",
    "            \n",
    "            # 元画像読み込み（日本語パス対応）\n",
    "            original = read_image_japanese_path(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if original is not None:\n",
    "                # 前処理適用\n",
    "                processed = preprocess_image_with_params(img_path)\n",
    "                \n",
    "                if processed is not None:\n",
    "                    # 比較表示\n",
    "                    show_image_comparison(\n",
    "                        original, \n",
    "                        processed, \n",
    "                        f\"Preprocessing Result: {os.path.basename(img_path)}\",\n",
    "                        \"Default Parameters\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"前処理に失敗: {img_path}\")\n",
    "            else:\n",
    "                print(f\"元画像の読み込みに失敗: {img_path}\")\n",
    "        else:\n",
    "            print(f\"画像が見つかりません: {img_path}\")\n",
    "\n",
    "# 簡単なテスト用関数\n",
    "def quick_test_image_loading():\n",
    "    \"\"\"画像読み込みのクイックテスト\"\"\"\n",
    "    test_path = r\"input\\背景カットなし\\sample\\OK\\OK1.png\"\n",
    "    \n",
    "    print(\"=== 画像読み込みテスト ===\")\n",
    "    print(f\"テストパス: {test_path}\")\n",
    "    print(f\"ファイル存在: {os.path.exists(test_path)}\")\n",
    "    \n",
    "    # 標準のcv2.imread\n",
    "    img1 = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "    print(f\"標準cv2.imread: {'成功' if img1 is not None else '失敗'}\")\n",
    "    \n",
    "    # 日本語パス対応版\n",
    "    img2 = read_image_japanese_path(test_path, cv2.IMREAD_GRAYSCALE)\n",
    "    print(f\"日本語パス対応版: {'成功' if img2 is not None else '失敗'}\")\n",
    "    \n",
    "    if img2 is not None:\n",
    "        print(f\"画像サイズ: {img2.shape}\")\n",
    "        print(f\"データ型: {img2.dtype}\")\n",
    "        print(f\"値の範囲: {img2.min()} - {img2.max()}\")\n",
    "\n",
    "# クイックテストを実行\n",
    "quick_test_image_loading()\n",
    "\n",
    "print(\"\\n=== 異なる画像でのテスト ===\")\n",
    "test_different_images()\n",
    "\n",
    "print(\"\\n=== パラメータ調整のヒント ===\")\n",
    "print(\"• 暗い画像: gamma を小さく (0.5-1.0)\")\n",
    "print(\"• 明るい画像: gamma を大きく (1.5-2.0)\")\n",
    "print(\"• コントラストが低い: alpha を大きく (1.5-2.0)\")\n",
    "print(\"• ノイズが多い: denoise_h を大きく (50-100)\")\n",
    "print(\"• エッジが弱い: sharpen_strength を 'strong' に\")\n",
    "print(\"• 背景が多い: crop_ratio を小さく (0.5-0.6)\")\n",
    "\n",
    "print(\"\\n=== 修正された機能 ===\")\n",
    "print(\"✓ 日本語パスに対応した画像読み込み\")\n",
    "print(\"✓ エラーハンドリングの改善\")\n",
    "print(\"✓ 画像読み込みテスト機能の追加\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
