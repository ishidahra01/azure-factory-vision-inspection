{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from functools import partial\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6721d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Azure Storage Blob configuration\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "BLOB_CONTAINER_NAME = os.getenv(\"BLOB_CONTAINER_NAME\")\n",
    "\n",
    "# Azure OpenAI configuration\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AOAI_API_VERSION = '2025-03-01-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142b645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_service_client():\n",
    "    \"\"\"Returns a BlobServiceClient instance.\"\"\"\n",
    "    return BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "\n",
    "def upload_to_blob(file_path, blob_name):\n",
    "    \"\"\"\n",
    "    Uploads a file to Azure Blob Storage and returns its URL with SAS token.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the local file\n",
    "        blob_name: Name to use in blob storage\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (blob_url, sas_token)\n",
    "    \"\"\"\n",
    "    blob_service_client = get_blob_service_client()\n",
    "    blob_client = blob_service_client.get_blob_client(container=BLOB_CONTAINER_NAME, blob=blob_name)\n",
    "    \n",
    "    with open(file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True)\n",
    "    \n",
    "    start_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "    expiry_time = start_time + datetime.timedelta(days=1)\n",
    "\n",
    "    # Generate SAS token\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_client.account_name,\n",
    "        container_name=blob_client.container_name,\n",
    "        blob_name=blob_client.blob_name,\n",
    "        account_key=blob_service_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=expiry_time,\n",
    "        start=start_time\n",
    "    )\n",
    "    \n",
    "    blob_url = blob_client.url\n",
    "    return blob_url, sas_token\n",
    "\n",
    "def get_openai_client():\n",
    "    \"\"\"Returns an AzureOpenAI client instance for GPT-4o model.\"\"\"\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AOAI_API_VERSION\n",
    "    )\n",
    "    return client\n",
    "\n",
    "# 段階的分類用のPydanticモデル\n",
    "class StepOneResult(BaseModel):\n",
    "    \"\"\"Step 1: OK/NG二値分類の結果\"\"\"\n",
    "    classification: Literal[\"OK\", \"NG\"]\n",
    "    reasoning: str\n",
    "    confidence: int = Field(\n",
    "        ...,\n",
    "        ge=1,\n",
    "        le=3,\n",
    "        description=\"分類の確信度（1〜3の整数：3=確実、2=一般的根拠あり、1=根拠なし/判断不能）\"\n",
    "    )\n",
    "\n",
    "class StepTwoResult(BaseModel):\n",
    "    \"\"\"Step 2: 汚れ/加工不良二値分類の結果\"\"\"\n",
    "    classification: Literal[\"汚れ\", \"加工不良\"]\n",
    "    reasoning: str\n",
    "    confidence: int = Field(\n",
    "        ...,\n",
    "        ge=1,\n",
    "        le=3,\n",
    "        description=\"分類の確信度（1〜3の整数：3=確実、2=一般的根拠あり、1=根拠なし/判断不能）\"\n",
    "    )\n",
    "\n",
    "class StepThreeResult(BaseModel):\n",
    "    \"\"\"Step 3: 欠け/削り節二値分類の結果\"\"\"\n",
    "    classification: Literal[\"欠け\", \"削り節\"]\n",
    "    reasoning: str\n",
    "    confidence: int = Field(\n",
    "        ...,\n",
    "        ge=1,\n",
    "        le=3,\n",
    "        description=\"分類の確信度（1〜3の整数：3=確実、2=一般的根拠あり、1=根拠なし/判断不能）\"\n",
    "    )\n",
    "\n",
    "# 最終分類結果\n",
    "class ClassificationResult(BaseModel):\n",
    "    \"\"\"最終的な分類結果\"\"\"\n",
    "    final_classification: Literal[\"OK\", \"汚れ\", \"欠け\", \"削り節\"]\n",
    "    step_one: StepOneResult\n",
    "    step_two: StepTwoResult = None\n",
    "    step_three: StepThreeResult = None\n",
    "    overall_confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0.0,\n",
    "        le=3.0,\n",
    "        description=\"全体的な確信度（1〜3の範囲）\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_collage_from_urls(image_urls, labels, title=\"Comparison\", image_size=(300, 300)):\n",
    "    \"\"\"\n",
    "    Create a collage image from two image URLs with labels\n",
    "    \n",
    "    Args:\n",
    "        image_urls: List of image URLs (expects 2 URLs)\n",
    "        labels: List of labels for each image (expects 2 labels)\n",
    "        title: Title for the collage\n",
    "        image_size: Size to resize each image to (width, height)\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image object containing the collage\n",
    "    \"\"\"\n",
    "    if len(image_urls) != 2 or len(labels) != 2:\n",
    "        raise ValueError(\"Expected exactly 2 image URLs and 2 labels\")\n",
    "    \n",
    "    # Download and process images\n",
    "    images = []\n",
    "    for url in image_urls:\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize(image_size, Image.Resampling.LANCZOS)\n",
    "        images.append(img)\n",
    "    \n",
    "    # Create collage canvas\n",
    "    canvas_width = image_size[0] * 2 + 60  # Extra space for labels and margins\n",
    "    canvas_height = image_size[1] + 100    # Extra space for title and labels\n",
    "    collage = Image.new('RGB', (canvas_width, canvas_height), 'white')\n",
    "    \n",
    "    # Try to use a better font, fall back to default if not available\n",
    "    try:\n",
    "        font_title = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "        font_label = ImageFont.truetype(\"arial.ttf\", 18)\n",
    "    except:\n",
    "        try:\n",
    "            font_title = ImageFont.truetype(\"DejaVuSans.ttf\", 24)\n",
    "            font_label = ImageFont.truetype(\"DejaVuSans.ttf\", 18)\n",
    "        except:\n",
    "            font_title = ImageFont.load_default()\n",
    "            font_label = ImageFont.load_default()\n",
    "    \n",
    "    draw = ImageDraw.Draw(collage)\n",
    "    \n",
    "    # Add title\n",
    "    title_bbox = draw.textbbox((0, 0), title, font=font_title)\n",
    "    title_width = title_bbox[2] - title_bbox[0]\n",
    "    title_x = (canvas_width - title_width) // 2\n",
    "    draw.text((title_x, 10), title, fill='black', font=font_title)\n",
    "    \n",
    "    # Add images and labels\n",
    "    y_offset = 50\n",
    "    x_positions = [20, image_size[0] + 40]\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        # Paste image\n",
    "        collage.paste(img, (x_positions[i], y_offset))\n",
    "        \n",
    "        # Add label below image\n",
    "        label_bbox = draw.textbbox((0, 0), label, font=font_label)\n",
    "        label_width = label_bbox[2] - label_bbox[0]\n",
    "        label_x = x_positions[i] + (image_size[0] - label_width) // 2\n",
    "        label_y = y_offset + image_size[1] + 10\n",
    "        draw.text((label_x, label_y), label, fill='black', font=font_label)\n",
    "    \n",
    "    return collage\n",
    "\n",
    "def upload_pil_image_to_blob(pil_image, blob_name, format='PNG'):\n",
    "    \"\"\"\n",
    "    Upload a PIL image to Azure Blob Storage\n",
    "    \n",
    "    Args:\n",
    "        pil_image: PIL Image object\n",
    "        blob_name: Name for the blob\n",
    "        format: Image format (default: PNG)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (blob_url, sas_token)\n",
    "    \"\"\"\n",
    "    # Convert PIL image to bytes\n",
    "    img_buffer = BytesIO()\n",
    "    pil_image.save(img_buffer, format=format)\n",
    "    img_buffer.seek(0)\n",
    "    \n",
    "    blob_service_client = get_blob_service_client()\n",
    "    blob_client = blob_service_client.get_blob_client(\n",
    "        container=BLOB_CONTAINER_NAME, \n",
    "        blob=blob_name\n",
    "    )\n",
    "    \n",
    "    # Upload the image\n",
    "    blob_client.upload_blob(img_buffer.getvalue(), overwrite=True)\n",
    "    \n",
    "    # Generate SAS token\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=blob_service_client.account_name,\n",
    "        container_name=BLOB_CONTAINER_NAME,\n",
    "        blob_name=blob_name,\n",
    "        account_key=blob_service_client.credential.account_key,\n",
    "        permission=BlobSasPermissions(read=True),\n",
    "        expiry=datetime.datetime.utcnow() + datetime.timedelta(hours=24)\n",
    "    )\n",
    "    \n",
    "    blob_url = blob_client.url\n",
    "    return blob_url, sas_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa328a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_images_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Upload all images from a folder structure to Blob Storage.\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to the input folder\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with image paths as keys and (blob_url, sas_token) as values\n",
    "    \"\"\"\n",
    "    uploaded_images = {}\n",
    "    folder_path = Path(folder_path)\n",
    "    \n",
    "    for image_file in folder_path.rglob(\"*.png\"):\n",
    "        # Create blob name preserving folder structure\n",
    "        relative_path = image_file.relative_to(folder_path)\n",
    "        blob_name = str(relative_path).replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        try:\n",
    "            blob_url, sas_token = upload_to_blob(str(image_file), blob_name)\n",
    "            full_url = f\"{blob_url}?{sas_token}\"\n",
    "            uploaded_images[str(image_file)] = full_url\n",
    "            print(f\"Uploaded: {blob_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {image_file}: {e}\")\n",
    "    \n",
    "    return uploaded_images\n",
    "\n",
    "def load_sample_images(uploaded_images, sample_folder=\"sample\"):\n",
    "    \"\"\"\n",
    "    Load sample images for few-shot learning.\n",
    "    \n",
    "    Args:\n",
    "        uploaded_images: Dictionary of uploaded images\n",
    "        sample_folder: Folder name to look for (default: \"sample\")\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with labels as keys and list of image URLs as values\n",
    "    \"\"\"\n",
    "    samples = {\"OK\": [], \"汚れ\": [], \"欠け\": [], \"削り節\": []}\n",
    "    \n",
    "    for image_path, url in uploaded_images.items():\n",
    "        # Normalize path separators and check if it contains sample folder\n",
    "        normalized_path = image_path.replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        if f\"/{sample_folder}/\" in normalized_path or normalized_path.endswith(f\"/{sample_folder}\"):\n",
    "            # Extract label from path - look for any of our target labels\n",
    "            for label in samples.keys():\n",
    "                if f\"/{label}/\" in normalized_path or f\"\\\\{label}\\\\\" in image_path:\n",
    "                    samples[label].append(url)\n",
    "                    print(f\"Added {label} sample: {Path(image_path).name}\")\n",
    "                    break\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def create_step_one_messages_with_collage(sample_images):\n",
    "    \"\"\"\n",
    "    Step 1: OK/NG二値分類用のメッセージをコラージュで作成\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"あなたは製造業の品質検査の専門家です。\n",
    "\n",
    "以下のFew-shotサンプルでは、左側にOK（良品）の例、右側にNG（不良品）の例を示し、それぞれの特徴の説明を提供します。\n",
    "これらの見分け方の例に基づいて、実際の画像データを1つのラベル（OKまたはNG）に分類してください。\n",
    "\n",
    "─── 分類定義 ───\n",
    "• OK（良品）: 製品の外観に異常がなく、形状・表面状態ともに規定の仕様範囲内\n",
    "• NG（不良品）: 製品に何らかの異常があり、品質基準を満たさない状態\n",
    "\n",
    "─── 確信度定義（3段階）───\n",
    "• 3：確実、はっきり判断可能\n",
    "• 2：一般的な根拠あり\n",
    "• 1：根拠なし、判断不能、そう見えなくもない\n",
    "\n",
    "必ず「OK」または「NG」のどちらかに分類し、その理由と確信度を提供してください。\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # OK vs NG サンプルコラージュを作成\n",
    "    ok_reasoning = [\n",
    "        \"画像内の部品を詳細に観察した結果、製品の表面は滑らかで均一な仕上がりを示しており、欠け・割れ・ヒビは一切確認できません。エッジ部分も設計通りの形状を保持し、異物付着や汚れも見当たりません。全体的に規定の仕様範囲内の良好な状態です。\",\n",
    "        \"画像内の部品を詳細に観察した結果、製品の表面は滑らかで均一な仕上がりを示していますが、部品奥方向のエッジで切削くずの付着があるようにも見えますが非常に極小なため規定の仕様範囲内の良好な状態と判断できます。\",\n",
    "        \"画像内の部品を詳細に観察した結果、製品の表面は滑らかで均一な仕上がりを示していますが、部品奥方向と上部のエッジで切削くずの付着があるようにも見えますが非常に極小なため規定の仕様範囲内の良好な状態と判断できます。\",\n",
    "    ]\n",
    "    \n",
    "    ng_reasoning = [\n",
    "        \"部品表面に基材とは異なる濃いグレーの色調の斜めの線がはっきりと確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品上部に明確な欠落が確認でき、製品の品質基準を満たさない不良品です。\", \n",
    "        \"製品上部と奥方向のエッジ部分に大きな切削くずの付着が確認でき、品質基準を満たさない不良品です。\"\n",
    "    ]\n",
    "    \n",
    "    # Create collages for OK vs NG comparison\n",
    "    ng_samples = []\n",
    "    ng_labels = [\"汚れ\", \"欠け\", \"削り節\"]\n",
    "    for label in ng_labels:\n",
    "        if sample_images[label]:\n",
    "            ng_samples.append(sample_images[label][0])\n",
    "    \n",
    "    for i in range(min(len(sample_images[\"OK\"]), len(ng_samples), 3)):\n",
    "        # Create collage with OK (left) vs NG (right)\n",
    "        collage = create_collage_from_urls(\n",
    "            [sample_images[\"OK\"][i], ng_samples[i]], \n",
    "            [\"OK（良品）\", \"NG（不良品）\"], \n",
    "            f\"品質検査比較例 {i+1}\"\n",
    "        )\n",
    "        \n",
    "        # Upload collage to blob storage\n",
    "        collage_blob_name = f\"collages/step1_comparison_{i+1}.png\"\n",
    "        blob_url, sas_token = upload_pil_image_to_blob(collage, collage_blob_name)\n",
    "        collage_url = f\"{blob_url}?{sas_token}\"\n",
    "        \n",
    "        # Create explanation for the comparison\n",
    "        comparison_explanation = f\"\"\"左側（OK）の特徴: {ok_reasoning[i]}\n",
    "\n",
    "右側（NG）の特徴: {ng_reasoning[i]}\n",
    "\n",
    "この比較例から、良品と不良品の違いを学習し、同様の基準で新しい画像を分類してください。\"\"\"\n",
    "        \n",
    "        messages.extend([\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"この比較画像を参考に、OK/NGの見分け方を教えてください。\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": collage_url, \"detail\": \"high\"}}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": comparison_explanation\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    return messages\n",
    "\n",
    "# 元の関数も保持（後方互換性のため）\n",
    "def create_step_one_messages(sample_images):\n",
    "    \"\"\"\n",
    "    Step 1: OK/NG二値分類用のメッセージを作成（従来版）\n",
    "    \"\"\"\n",
    "    return create_step_one_messages_with_collage(sample_images)\n",
    "\n",
    "def create_step_two_messages_with_collage(sample_images):\n",
    "    \"\"\"\n",
    "    Step 2: 汚れ/加工不良二値分類用のメッセージをコラージュで作成\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"あなたは製造業の品質検査の専門家です。\n",
    "\n",
    "以下のFew-shotサンプルでは、左側に汚れの例、右側に加工不良の例を示し、それぞれの特徴の説明を提供します。\n",
    "これらの見分け方の例に基づいて、実際のNG部品画像データを1つのラベル（汚れまたは加工不良）に分類してください。\n",
    "\n",
    "─── 分類定義 ───\n",
    "• 汚れ: 表面に油脂・ほこり・粉じん・液体シミなどの異物が付着し、拭いても残るもの\n",
    "• 加工不良: 製造工程で発生した物理的な損傷や加工ミス、切削くずの残留\n",
    "\n",
    "─── 確信度定義（3段階）───\n",
    "• 3：確実、はっきり判断可能\n",
    "• 2：一般的な根拠あり  \n",
    "• 1：根拠なし、判断不能、そう見えなくもない\n",
    "\n",
    "必ず「汚れ」または「加工不良」のどちらかに分類し、その理由と確信度を提供してください。\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    stain_reasoning = [\n",
    "        \"部品表面に基材とは異なる濃いグレーの色調の斜めの線がはっきりと確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品表面に基材とは異なる濃いグレーの色調の太めの線が部品上部から下部にかけて確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品中央付近に基材とは異なる色調の付着物が確認できます。品質基準を満たさない不良品と判断されます。\"\n",
    "    ]\n",
    "    \n",
    "    defect_reasoning = [\n",
    "        \"部品上部に明確な欠落が確認でき、製品の品質基準を満たさない不良品です。\",\n",
    "        \"製品上部と奥方向のエッジ部分に大きな切削くずの付着が確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品奥方向のエッジ部分に非常に大きな切削くずの付着が確認でき、品質基準を満たさない不良品です。\"\n",
    "    ]\n",
    "    \n",
    "    # Create collages for 汚れ vs 加工不良 comparison\n",
    "    defect_samples = []\n",
    "    defect_labels = [\"欠け\", \"削り節\"]\n",
    "    for label in defect_labels:\n",
    "        if sample_images[label]:\n",
    "            defect_samples.extend(sample_images[label][:2])\n",
    "    \n",
    "    for i in range(min(len(sample_images[\"汚れ\"]), len(defect_samples), 3)):\n",
    "        # Create collage with 汚れ (left) vs 加工不良 (right)\n",
    "        collage = create_collage_from_urls(\n",
    "            [sample_images[\"汚れ\"][i], defect_samples[i]], \n",
    "            [\"汚れ\", \"加工不良\"], \n",
    "            f\"汚れ vs 加工不良 比較例 {i+1}\"\n",
    "        )\n",
    "        \n",
    "        # Upload collage to blob storage\n",
    "        collage_blob_name = f\"collages/step2_comparison_{i+1}.png\"\n",
    "        blob_url, sas_token = upload_pil_image_to_blob(collage, collage_blob_name)\n",
    "        collage_url = f\"{blob_url}?{sas_token}\"\n",
    "        \n",
    "        # Create explanation for the comparison\n",
    "        comparison_explanation = f\"\"\"左側（汚れ）の特徴: {stain_reasoning[i]}\n",
    "\n",
    "右側（加工不良）の特徴: {defect_reasoning[i]}\n",
    "\n",
    "この比較例から、汚れと加工不良の違いを学習し、同様の基準で新しいNG部品画像を分類してください。\"\"\"\n",
    "        \n",
    "        messages.extend([\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"この比較画像を参考に、汚れ/加工不良の見分け方を教えてください。\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": collage_url, \"detail\": \"high\"}}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": comparison_explanation\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def create_step_three_messages_with_collage(sample_images):\n",
    "    \"\"\"\n",
    "    Step 3: 欠け/削り節二値分類用のメッセージをコラージュで作成\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"あなたは製造業の品質検査の専門家です。\n",
    "\n",
    "以下のFew-shotサンプルでは、左側に欠けの例、右側に削り節の例を示し、それぞれの特徴の説明を提供します。\n",
    "これらの見分け方の例に基づいて、実際の加工不良部品画像データを1つのラベル（欠けまたは削り節）に分類してください。\n",
    "\n",
    "─── 分類定義 ───\n",
    "• 欠け: 表面またはエッジの一部が物理的に欠落し、凹状の傷・穴があるもの\n",
    "• 削り節: 製造工程で発生した切削くずが製品上部やエッジに残留・飛び出しているもの\n",
    "\n",
    "─── 確信度定義（3段階）───\n",
    "• 3：確実、はっきり判断可能\n",
    "• 2：一般的な根拠あり\n",
    "• 1：根拠なし、判断不能、そう見えなくもない\n",
    "\n",
    "必ず「欠け」または「削り節」のどちらかに分類し、その理由と確信度を提供してください。\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    crack_reasoning = [\n",
    "        \"部品上部に明確な欠落が確認でき、製品の品質基準を満たさない不良品です。\",\n",
    "        \"部品上部に明確な欠落が複数個所確認でき、製品の品質基準を満たさない不良品です。欠けた部分が飛び出して削り節のように見える部分もありますが、欠けが確認できるため欠けと判断されます。\",\n",
    "        \"部品上部中央付近に明確な欠落が確認でき、製品の品質基準を満たさない不良品です。\"\n",
    "    ]\n",
    "    \n",
    "    chips_reasoning = [\n",
    "        \"製品上部と奥方向のエッジ部分に大きな切削くずの付着が確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品奥方向のエッジ部分に非常に大きな切削くずの付着が確認でき、品質基準を満たさない不良品です。\",\n",
    "        \"部品中央付近に切削くずの付着が確認でき、品質基準を満たさない不良品です。\"\n",
    "    ]\n",
    "    \n",
    "    # Create collages for 欠け vs 削り節 comparison  \n",
    "    for i in range(min(len(sample_images[\"欠け\"]), len(sample_images[\"削り節\"]), 3)):\n",
    "        # Create collage with 欠け (left) vs 削り節 (right)\n",
    "        collage = create_collage_from_urls(\n",
    "            [sample_images[\"欠け\"][i], sample_images[\"削り節\"][i]], \n",
    "            [\"欠け\", \"削り節\"], \n",
    "            f\"欠け vs 削り節 比較例 {i+1}\"\n",
    "        )\n",
    "        \n",
    "        # Upload collage to blob storage\n",
    "        collage_blob_name = f\"collages/step3_comparison_{i+1}.png\"\n",
    "        blob_url, sas_token = upload_pil_image_to_blob(collage, collage_blob_name)\n",
    "        collage_url = f\"{blob_url}?{sas_token}\"\n",
    "        \n",
    "        # Create explanation for the comparison\n",
    "        comparison_explanation = f\"\"\"左側（欠け）の特徴: {crack_reasoning[i]}\n",
    "\n",
    "右側（削り節）の特徴: {chips_reasoning[i]}\n",
    "\n",
    "この比較例から、欠けと削り節の違いを学習し、同様の基準で新しい加工不良部品画像を分類してください。\"\"\"\n",
    "        \n",
    "        messages.extend([\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"この比較画像を参考に、欠け/削り節の見分け方を教えてください。\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": collage_url, \"detail\": \"high\"}}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": comparison_explanation\n",
    "            }\n",
    "        ])\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def classify_image(client, image_url, few_shot_messages):\n",
    "    \"\"\"\n",
    "    Classify a single image using Azure OpenAI with Pydantic structured output.\n",
    "    \"\"\"\n",
    "    messages = few_shot_messages.copy()\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"上記の比較例を参考にして、この部品の画像を分類してください。Few-shotの見分け方の例に基づいて判定してください。\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url, \"detail\": \"high\"}}\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4.1\",  # Replace with your actual model deployment name\n",
    "            messages=messages,\n",
    "            response_format=ClassificationResult,\n",
    "            max_tokens=1000,\n",
    "            temperature=0  # Lower temperature for more consistent results\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message.parsed\n",
    "        return {\n",
    "            \"classification\": result.classification,\n",
    "            \"reasoning\": result.reasoning,\n",
    "            \"confidence\": result.confidence\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying image: {e}\")\n",
    "        return {\n",
    "            \"classification\": \"Error\",\n",
    "            \"reasoning\": f\"Classification failed: {str(e)}\",\n",
    "            \"confidence\": 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7123e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update existing functions to use collage versions by default\n",
    "def create_step_two_messages(sample_images):\n",
    "    \"\"\"\n",
    "    Step 2: 汚れ/加工不良二値分類用のメッセージを作成（コラージュ版を使用）\n",
    "    \"\"\"\n",
    "    return create_step_two_messages_with_collage(sample_images)\n",
    "\n",
    "def create_step_three_messages(sample_images):\n",
    "    \"\"\"\n",
    "    Step 3: 欠け/削り節二値分類用のメッセージを作成（コラージュ版を使用）\n",
    "    \"\"\"\n",
    "    return create_step_three_messages_with_collage(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5086b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_binary_step(client, image_url, messages, result_class):\n",
    "    \"\"\"\n",
    "    Execute a single step of binary classification.\n",
    "    \n",
    "    Args:\n",
    "        client: Azure OpenAI client\n",
    "        image_url: Image URL to classify\n",
    "        messages: Few-shot messages for this step\n",
    "        result_class: Pydantic model class for this step\n",
    "    \n",
    "    Returns:\n",
    "        dict: Classification result\n",
    "    \"\"\"\n",
    "    step_messages = messages.copy()\n",
    "    step_messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"上記の比較例を参考にして、この部品の画像を分類してください。Few-shotの見分け方の例に基づいて判定してください。\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_url, \"detail\": \"high\"}}\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4.1\",  # Replace with your actual model deployment name\n",
    "            messages=step_messages,\n",
    "            response_format=result_class,\n",
    "            max_tokens=1000,\n",
    "            temperature=0  # Lower temperature for more consistent results\n",
    "        )\n",
    "        \n",
    "        result = completion.choices[0].message.parsed\n",
    "        return {\n",
    "            \"classification\": result.classification,\n",
    "            \"reasoning\": result.reasoning,\n",
    "            \"confidence\": result.confidence\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in classification step: {e}\")\n",
    "        return {\"classification\": \"ERROR\", \"reasoning\": f\"Error: {e}\", \"confidence\": 0}\n",
    "\n",
    "def classify_image_hierarchical(client, image_url, step_messages):\n",
    "    \"\"\"\n",
    "    Perform hierarchical binary classification: OK/NG → 汚れ/加工不良 → 欠け/削り節\n",
    "    \n",
    "    Args:\n",
    "        client: Azure OpenAI client\n",
    "        image_url: Image URL to classify\n",
    "        step_messages: Dict containing messages for each step\n",
    "    \n",
    "    Returns:\n",
    "        dict: Complete classification result\n",
    "    \"\"\"\n",
    "    # Step 1: OK/NG classification\n",
    "    step_one_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_one\"], StepOneResult\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        \"step_one\": step_one_result,\n",
    "        \"step_two\": None,\n",
    "        \"step_three\": None,\n",
    "        \"final_classification\": step_one_result[\"classification\"],\n",
    "        \"overall_confidence\": step_one_result[\"confidence\"]\n",
    "    }\n",
    "    \n",
    "    # If OK, stop here\n",
    "    if step_one_result[\"classification\"] == \"OK\":\n",
    "        return result\n",
    "    \n",
    "    # Step 2: 汚れ/加工不良 classification (for NG items)\n",
    "    step_two_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_two\"], StepTwoResult\n",
    "    )\n",
    "    result[\"step_two\"] = step_two_result\n",
    "    \n",
    "    # If 汚れ, stop here\n",
    "    if step_two_result[\"classification\"] == \"汚れ\":\n",
    "        result[\"final_classification\"] = \"汚れ\"\n",
    "        result[\"overall_confidence\"] = (step_one_result[\"confidence\"] + step_two_result[\"confidence\"]) / 2\n",
    "        return result\n",
    "    \n",
    "    # Step 3: 欠け/削り節 classification (for 加工不良 items)\n",
    "    step_three_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_three\"], StepThreeResult\n",
    "    )\n",
    "    result[\"step_three\"] = step_three_result\n",
    "    result[\"final_classification\"] = step_three_result[\"classification\"]\n",
    "    result[\"overall_confidence\"] = (\n",
    "        step_one_result[\"confidence\"] + \n",
    "        step_two_result[\"confidence\"] + \n",
    "        step_three_result[\"confidence\"]\n",
    "    ) / 3\n",
    "    \n",
    "    return result\n",
    "\n",
    "def classify_image_hierarchical_wrapper(args):\n",
    "    \"\"\"\n",
    "    Wrapper function for parallel hierarchical classification.\n",
    "    \"\"\"\n",
    "    image_url, true_label, image_path, client, step_messages, index, total = args\n",
    "    \n",
    "    print(f\"[{index+1}/{total}] Hierarchical classification: {Path(image_path).name}\")\n",
    "    \n",
    "    try:\n",
    "        result = classify_image_hierarchical(client, image_url, step_messages)\n",
    "        \n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'image_url': image_url,\n",
    "            'true_label': true_label,\n",
    "            'predicted': result['final_classification'],\n",
    "            'step_one_classification': result['step_one']['classification'],\n",
    "            'step_one_confidence': result['step_one']['confidence'],\n",
    "            'step_one_reasoning': result['step_one']['reasoning'],\n",
    "            'step_two_classification': result['step_two']['classification'] if result['step_two'] else None,\n",
    "            'step_two_confidence': result['step_two']['confidence'] if result['step_two'] else None,\n",
    "            'step_two_reasoning': result['step_two']['reasoning'] if result['step_two'] else None,\n",
    "            'step_three_classification': result['step_three']['classification'] if result['step_three'] else None,\n",
    "            'step_three_confidence': result['step_three']['confidence'] if result['step_three'] else None,\n",
    "            'step_three_reasoning': result['step_three']['reasoning'] if result['step_three'] else None,\n",
    "            'overall_confidence': result['overall_confidence'],\n",
    "            'status': 'success',\n",
    "            'index': index\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hierarchical classification {Path(image_path).name}: {e}\")\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'image_url': image_url,\n",
    "            'true_label': true_label,\n",
    "            'predicted': 'ERROR',\n",
    "            'step_one_classification': 'ERROR',\n",
    "            'step_one_confidence': 0,\n",
    "            'step_one_reasoning': f'Classification failed: {str(e)}',\n",
    "            'step_two_classification': None,\n",
    "            'step_two_confidence': None,\n",
    "            'step_two_reasoning': None,\n",
    "            'step_three_classification': None,\n",
    "            'step_three_confidence': None,\n",
    "            'step_three_reasoning': None,\n",
    "            'overall_confidence': 0,\n",
    "            'status': 'error',\n",
    "            'index': index\n",
    "        }\n",
    "\n",
    "def classify_images_hierarchical_parallel(test_data, client, step_messages, max_workers=3):\n",
    "    \"\"\"\n",
    "    Classify images using hierarchical binary classification in parallel.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(test_data)\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args_list = [\n",
    "        (image_url, true_label, image_path, client, step_messages, i, total)\n",
    "        for i, (image_url, true_label, image_path) in enumerate(test_data)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Starting hierarchical classification with {max_workers} workers...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_args = {executor.submit(classify_image_hierarchical_wrapper, args): args for args in args_list}\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_args):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                # Print progress\n",
    "                completed = len(results)\n",
    "                elapsed = time.time() - start_time\n",
    "                avg_time = elapsed / completed\n",
    "                eta = avg_time * (total - completed)\n",
    "                \n",
    "                if completed % 5 == 0 or completed == total:\n",
    "                    print(f\"Progress: {completed}/{total} ({completed/total*100:.1f}%) - \"\n",
    "                          f\"ETA: {eta:.1f}s\")\n",
    "                          \n",
    "            except Exception as e:\n",
    "                print(f\"Future failed: {e}\")\n",
    "    \n",
    "    # Sort results by index to maintain order\n",
    "    results.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nHierarchical classification completed in {total_time:.1f}s\")\n",
    "    print(f\"Average time per image: {total_time/total:.2f}s\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_images(uploaded_images, test_folder=\"test\"):\n",
    "    \"\"\"\n",
    "    Load test images with their true labels.\n",
    "    \n",
    "    Args:\n",
    "        uploaded_images: Dictionary of uploaded images\n",
    "        test_folder: Folder name to look for (default: \"test\")\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples (image_url, true_label, image_path)\n",
    "    \"\"\"\n",
    "    test_data = []\n",
    "    \n",
    "    for image_path, url in uploaded_images.items():\n",
    "        # Normalize path separators and check if it contains test folder\n",
    "        normalized_path = image_path.replace(\"\\\\\", \"/\")\n",
    "        \n",
    "        if f\"/{test_folder}/\" in normalized_path:\n",
    "            # Extract true label from folder structure\n",
    "            for label in [\"OK\", \"汚れ\", \"欠け\", \"削り節\"]:\n",
    "                if f\"/{label}/\" in normalized_path or f\"\\\\{label}\\\\\" in image_path:\n",
    "                    test_data.append((url, label, image_path))\n",
    "                    break\n",
    "    \n",
    "    return test_data\n",
    "\n",
    "def get_openai_client():\n",
    "    \"\"\"\n",
    "    Initialize Azure OpenAI client.\n",
    "    \"\"\"\n",
    "    return AzureOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AOAI_API_VERSION\n",
    "    )\n",
    "\n",
    "def evaluate_results(results_df):\n",
    "    \"\"\"\n",
    "    Evaluate classification results and create confusion matrix.\n",
    "    \"\"\"\n",
    "    # Calculate accuracy\n",
    "    accuracy = (results_df['predicted'] == results_df['true_label']).mean()\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(results_df['true_label'], results_df['predicted']))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    labels = [\"OK\", \"汚れ\", \"欠け\", \"削り節\"]\n",
    "    cm = confusion_matrix(results_df['true_label'], results_df['predicted'], labels=labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735059ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_hierarchical(client, image_url, step_messages):\n",
    "    \"\"\"\n",
    "    Execute hierarchical binary classification (Step 1 -> Step 2 -> Step 3).\n",
    "    \n",
    "    Args:\n",
    "        client: Azure OpenAI client\n",
    "        image_url: Image URL to classify\n",
    "        step_messages: Dictionary containing messages for each step\n",
    "    \n",
    "    Returns:\n",
    "        dict: Hierarchical classification result\n",
    "    \"\"\"\n",
    "    # Step 1: OK/NG classification\n",
    "    step_one_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_one\"], StepOneResult\n",
    "    )\n",
    "    \n",
    "    result = {\n",
    "        \"step_one\": step_one_result,\n",
    "        \"step_two\": None,\n",
    "        \"step_three\": None,\n",
    "        \"final_classification\": step_one_result[\"classification\"],\n",
    "        \"overall_confidence\": step_one_result[\"confidence\"]\n",
    "    }\n",
    "    \n",
    "    # If OK, stop here\n",
    "    if step_one_result[\"classification\"] == \"OK\":\n",
    "        return result\n",
    "    \n",
    "    # Step 2: 汚れ/加工不良 classification (for NG items)\n",
    "    step_two_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_two\"], StepTwoResult\n",
    "    )\n",
    "    result[\"step_two\"] = step_two_result\n",
    "    \n",
    "    # If 汚れ, stop here\n",
    "    if step_two_result[\"classification\"] == \"汚れ\":\n",
    "        result[\"final_classification\"] = \"汚れ\"\n",
    "        result[\"overall_confidence\"] = (step_one_result[\"confidence\"] + step_two_result[\"confidence\"]) / 2\n",
    "        return result\n",
    "    \n",
    "    # Step 3: 欠け/削り節 classification (for 加工不良 items)\n",
    "    step_three_result = classify_image_binary_step(\n",
    "        client, image_url, step_messages[\"step_three\"], StepThreeResult\n",
    "    )\n",
    "    result[\"step_three\"] = step_three_result\n",
    "    result[\"final_classification\"] = step_three_result[\"classification\"]\n",
    "    result[\"overall_confidence\"] = (\n",
    "        step_one_result[\"confidence\"] + \n",
    "        step_two_result[\"confidence\"] + \n",
    "        step_three_result[\"confidence\"]\n",
    "    ) / 3\n",
    "    \n",
    "    return result\n",
    "\n",
    "def classify_image_hierarchical_wrapper(args):\n",
    "    \"\"\"\n",
    "    Wrapper function for parallel hierarchical classification.\n",
    "    \"\"\"\n",
    "    image_url, true_label, image_path, client, step_messages, index, total = args\n",
    "    \n",
    "    print(f\"[{index+1}/{total}] Hierarchical classification: {Path(image_path).name}\")\n",
    "    \n",
    "    try:\n",
    "        result = classify_image_hierarchical(client, image_url, step_messages)\n",
    "        \n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'image_url': image_url,\n",
    "            'true_label': true_label,\n",
    "            'predicted': result['final_classification'],\n",
    "            'step_one_classification': result['step_one']['classification'],\n",
    "            'step_one_confidence': result['step_one']['confidence'],\n",
    "            'step_one_reasoning': result['step_one']['reasoning'],\n",
    "            'step_two_classification': result['step_two']['classification'] if result['step_two'] else None,\n",
    "            'step_two_confidence': result['step_two']['confidence'] if result['step_two'] else None,\n",
    "            'step_two_reasoning': result['step_two']['reasoning'] if result['step_two'] else None,\n",
    "            'step_three_classification': result['step_three']['classification'] if result['step_three'] else None,\n",
    "            'step_three_confidence': result['step_three']['confidence'] if result['step_three'] else None,\n",
    "            'step_three_reasoning': result['step_three']['reasoning'] if result['step_three'] else None,\n",
    "            'overall_confidence': result['overall_confidence'],\n",
    "            'status': 'success',\n",
    "            'index': index\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hierarchical classification {Path(image_path).name}: {e}\")\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'image_url': image_url,\n",
    "            'true_label': true_label,\n",
    "            'predicted': 'ERROR',\n",
    "            'step_one_classification': 'ERROR',\n",
    "            'step_one_confidence': 0,\n",
    "            'step_one_reasoning': f'Classification failed: {str(e)}',\n",
    "            'step_two_classification': None,\n",
    "            'step_two_confidence': None,\n",
    "            'step_two_reasoning': None,\n",
    "            'step_three_classification': None,\n",
    "            'step_three_confidence': None,\n",
    "            'step_three_reasoning': None,\n",
    "            'overall_confidence': 0,\n",
    "            'status': 'error',\n",
    "            'index': index\n",
    "        }\n",
    "\n",
    "def classify_images_hierarchical_parallel(test_data, client, step_messages, max_workers=3):\n",
    "    \"\"\"\n",
    "    Classify images using hierarchical binary classification in parallel.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = len(test_data)\n",
    "    \n",
    "    # Prepare arguments for parallel processing\n",
    "    args_list = [\n",
    "        (image_url, true_label, image_path, client, step_messages, i, total)\n",
    "        for i, (image_url, true_label, image_path) in enumerate(test_data)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Starting hierarchical classification with {max_workers} workers...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_args = {executor.submit(classify_image_hierarchical_wrapper, args): args for args in args_list}\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_args):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                # Print progress\n",
    "                completed = len(results)\n",
    "                elapsed = time.time() - start_time\n",
    "                avg_time = elapsed / completed\n",
    "                eta = avg_time * (total - completed)\n",
    "                \n",
    "                if completed % 5 == 0 or completed == total:\n",
    "                    print(f\"Progress: {completed}/{total} ({completed/total*100:.1f}%) - \"\n",
    "                          f\"ETA: {eta:.1f}s\")\n",
    "                          \n",
    "            except Exception as e:\n",
    "                print(f\"Future failed: {e}\")\n",
    "    \n",
    "    # Sort results by index to maintain order\n",
    "    results.sort(key=lambda x: x['index'])\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nHierarchical classification completed in {total_time:.1f}s\")\n",
    "    print(f\"Average time per image: {total_time/total:.2f}s\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8989ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all images from input/背景カットなし folder only\n",
    "print(\"Uploading images from 背景カットなし folder to Blob Storage...\")\n",
    "uploaded_images = upload_images_from_folder(\"input/背景カットなし\")\n",
    "print(f\"Uploaded {len(uploaded_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a732d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images for few-shot learning\n",
    "sample_images = load_sample_images(uploaded_images)\n",
    "print(\"Sample images loaded:\")\n",
    "for label, urls in sample_images.items():\n",
    "    print(f\"{label}: {len(urls)} images\")\n",
    "\n",
    "print(\"\\n🖼️ Creating collage-based few-shot learning messages...\")\n",
    "\n",
    "# Create step-wise messages for hierarchical classification using collages\n",
    "step_messages = {\n",
    "    \"step_one\": create_step_one_messages_with_collage(sample_images),\n",
    "    \"step_two\": create_step_two_messages_with_collage(sample_images),\n",
    "    \"step_three\": create_step_three_messages_with_collage(sample_images)\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ Created hierarchical classification messages with collages:\")\n",
    "print(f\"Step 1 (OK vs NG): {len(step_messages['step_one'])} messages\")\n",
    "print(f\"Step 2 (汚れ vs 加工不良): {len(step_messages['step_two'])} messages\")\n",
    "print(f\"Step 3 (欠け vs 削り節): {len(step_messages['step_three'])} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cebaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "test_data = load_test_images(uploaded_images)\n",
    "print(f\"Loaded {len(test_data)} test images\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = get_openai_client()\n",
    "\n",
    "# Configure parallel processing\n",
    "max_workers = 3  # Conservative setting for hierarchical classification\n",
    "print(f\"Using hierarchical binary classification with {max_workers} workers...\")\n",
    "\n",
    "# Execute hierarchical classification\n",
    "results = classify_images_hierarchical_parallel(test_data, client, step_messages, max_workers)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Remove the index and status columns if not needed for evaluation\n",
    "results_df = results_df.drop(['index', 'status'], axis=1, errors='ignore')\n",
    "\n",
    "print(\"\\nHierarchical classification completed!\")\n",
    "print(results_df[['image_path', 'true_label', 'predicted', 'step_one_classification']].head())\n",
    "\n",
    "# Show error summary\n",
    "error_count = len(results_df[results_df['predicted'] == 'ERROR'])\n",
    "if error_count > 0:\n",
    "    print(f\"\\nWarning: {error_count} images failed to classify\")\n",
    "    print(\"Error details:\")\n",
    "    error_df = results_df[results_df['predicted'] == 'ERROR']\n",
    "    for _, row in error_df.iterrows():\n",
    "        print(f\"  {Path(row['image_path']).name}: {row['step_one_reasoning']}\")\n",
    "\n",
    "# Show step-wise classification statistics\n",
    "print(f\"\\n=== Step-wise Classification Statistics ===\")\n",
    "print(f\"Step 1 (OK/NG) distribution:\")\n",
    "step_one_dist = results_df['step_one_classification'].value_counts()\n",
    "print(step_one_dist)\n",
    "\n",
    "ng_df = results_df[results_df['step_one_classification'] == 'NG']\n",
    "if len(ng_df) > 0:\n",
    "    print(f\"\\nStep 2 (汚れ/加工不良) distribution for NG items:\")\n",
    "    step_two_dist = ng_df['step_two_classification'].value_counts()\n",
    "    print(step_two_dist)\n",
    "    \n",
    "    defect_df = ng_df[ng_df['step_two_classification'] == '加工不良']\n",
    "    if len(defect_df) > 0:\n",
    "        print(f\"\\nStep 3 (欠け/削り節) distribution for 加工不良 items:\")\n",
    "        step_three_dist = defect_df['step_three_classification'].value_counts()\n",
    "        print(step_three_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08721e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate hierarchical classification results (excluding error cases)\n",
    "valid_results_df = results_df[results_df['predicted'] != 'ERROR'].copy()\n",
    "\n",
    "print(f\"=== Hierarchical Classification Evaluation ===\")\n",
    "print(f\"Valid results: {len(valid_results_df)}/{len(results_df)} ({len(valid_results_df)/len(results_df)*100:.1f}%)\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = (valid_results_df['predicted'] == valid_results_df['true_label']).mean()\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.3f}\")\n",
    "\n",
    "# Step-wise accuracy analysis\n",
    "print(f\"\\n=== Step-wise Accuracy Analysis ===\")\n",
    "\n",
    "# Step 1: OK/NG accuracy\n",
    "step1_true = valid_results_df['true_label'].apply(lambda x: 'OK' if x == 'OK' else 'NG')\n",
    "step1_pred = valid_results_df['step_one_classification']\n",
    "step1_accuracy = (step1_true == step1_pred).mean()\n",
    "print(f\"Step 1 (OK/NG) Accuracy: {step1_accuracy:.3f}\")\n",
    "\n",
    "# Step 2: 汚れ/加工不良 accuracy (for NG items only)\n",
    "ng_items = valid_results_df[valid_results_df['step_one_classification'] == 'NG']\n",
    "if len(ng_items) > 0:\n",
    "    step2_true = ng_items['true_label'].apply(lambda x: '汚れ' if x == '汚れ' else '加工不良')\n",
    "    step2_pred = ng_items['step_two_classification']\n",
    "    step2_accuracy = (step2_true == step2_pred).mean()\n",
    "    print(f\"Step 2 (汚れ/加工不良) Accuracy: {step2_accuracy:.3f} (on {len(ng_items)} NG items)\")\n",
    "\n",
    "# Step 3: 欠け/削り節 accuracy (for 加工不良 items only)\n",
    "defect_items = ng_items[ng_items['step_two_classification'] == '加工不良'] if len(ng_items) > 0 else pd.DataFrame()\n",
    "if len(defect_items) > 0:\n",
    "    step3_true = defect_items['true_label']\n",
    "    step3_pred = defect_items['step_three_classification']\n",
    "    step3_accuracy = (step3_true == step3_pred).mean()\n",
    "    print(f\"Step 3 (欠け/削り節) Accuracy: {step3_accuracy:.3f} (on {len(defect_items)} 加工不良 items)\")\n",
    "\n",
    "# Detailed classification report and confusion matrix\n",
    "print(f\"\\n=== Final Classification Report ===\")\n",
    "labels = [\"OK\", \"汚れ\", \"欠け\", \"削り節\"]\n",
    "print(classification_report(valid_results_df['true_label'], valid_results_df['predicted'], labels=labels))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(valid_results_df['true_label'], valid_results_df['predicted'], labels=labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Hierarchical Classification - Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Save detailed results with step information\n",
    "output_dir = 'analysis-results'\n",
    "if not os.path.exists(output_dir):\n",
    "\tos.makedirs(output_dir)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "results_filename = f'hierarchical_classification_results_{timestamp}.csv'\n",
    "results_df.to_csv(f\"{output_dir}/{results_filename}\", index=False, encoding='utf-8-sig')\n",
    "print(f\"\\nDetailed results saved to '{output_dir}/{results_filename}'\")\n",
    "\n",
    "# Display confidence statistics\n",
    "print(f\"\\n=== Confidence Statistics ===\")\n",
    "print(f\"Overall confidence: {valid_results_df['overall_confidence'].describe()}\")\n",
    "print(f\"Step 1 confidence: {valid_results_df['step_one_confidence'].describe()}\")\n",
    "\n",
    "if len(ng_items) > 0:\n",
    "    print(f\"Step 2 confidence: {ng_items['step_two_confidence'].describe()}\")\n",
    "if len(defect_items) > 0:\n",
    "    print(f\"Step 3 confidence: {defect_items['step_three_confidence'].describe()}\")\n",
    "\n",
    "# Show some example predictions with step details\n",
    "print(f\"\\n=== Example Hierarchical Predictions ===\")\n",
    "for idx, row in valid_results_df.head(3).iterrows():\n",
    "    print(f\"\\nImage: {Path(row['image_path']).name}\")\n",
    "    print(f\"True: {row['true_label']}, Final Predicted: {row['predicted']}\")\n",
    "    print(f\"Step 1: {row['step_one_classification']} (confidence: {row['step_one_confidence']})\")\n",
    "    if row['step_two_classification']:\n",
    "        print(f\"Step 2: {row['step_two_classification']} (confidence: {row['step_two_confidence']})\")\n",
    "    if row['step_three_classification']:\n",
    "        print(f\"Step 3: {row['step_three_classification']} (confidence: {row['step_three_confidence']})\")\n",
    "    print(f\"Overall confidence: {row['overall_confidence']:.1f}\")\n",
    "\n",
    "# Error analysis\n",
    "print(f\"\\n=== Error Analysis ===\")\n",
    "incorrect_predictions = valid_results_df[valid_results_df['predicted'] != valid_results_df['true_label']]\n",
    "if len(incorrect_predictions) > 0:\n",
    "    print(f\"Incorrect predictions: {len(incorrect_predictions)}\")\n",
    "    print(\"Error breakdown by true label:\")\n",
    "    error_breakdown = incorrect_predictions.groupby('true_label')['predicted'].value_counts()\n",
    "    print(error_breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 段階的二値分類の実行完了\n",
    "# \n",
    "# 実行手順:\n",
    "# 1. OK/NG の二値分類\n",
    "# 2. NG の場合 → 汚れ/加工不良 の二値分類  \n",
    "# 3. 加工不良の場合 → 欠け/削り節 の二値分類\n",
    "#\n",
    "# この段階的アプローチにより、各段階で特化した判定を行い、\n",
    "# 全体的な分類精度の向上を図っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e21d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 詳細誤り分析 - 各ステップの分類誤りを画像付きで表示\n",
    "# =============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def display_image_from_url(image_url, title=\"\"):\n",
    "    \"\"\"URLから画像を取得して表示（色味を正しく保持）\"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        # カラーモードを確認し、必要に応じてRGBに変換\n",
    "        if img.mode == 'RGBA':\n",
    "            # RGBAモードの場合、白背景でRGBに変換\n",
    "            background = Image.new('RGB', img.size, (255, 255, 255))\n",
    "            background.paste(img, mask=img.split()[-1])  # アルファチャンネルをマスクとして使用\n",
    "            img = background\n",
    "        elif img.mode == 'CMYK':\n",
    "            # CMYKモードの場合、RGBに変換\n",
    "            img = img.convert('RGB')\n",
    "        elif img.mode not in ['RGB', 'L']:\n",
    "            # その他のモードもRGBに変換\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"画像表示エラー: {e}\")\n",
    "\n",
    "def analyze_step_errors(results_df, step_name, true_col, pred_col, reasoning_col, max_samples=5):\n",
    "    \"\"\"各ステップの分類誤りを分析\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"📊 {step_name} 分類誤り分析\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 該当ステップの結果のみ抽出（NaNを除外）\n",
    "    step_df = results_df.dropna(subset=[pred_col])\n",
    "    \n",
    "    if len(step_df) == 0:\n",
    "        print(f\"❌ {step_name} のデータがありません\")\n",
    "        return\n",
    "    \n",
    "    # 誤分類を特定\n",
    "    errors = step_df[step_df[true_col] != step_df[pred_col]]\n",
    "    \n",
    "    print(f\"📈 分析対象: {len(step_df)} 件\")\n",
    "    print(f\"❌ 誤分類: {len(errors)} 件\")\n",
    "    print(f\"✅ 精度: {((len(step_df) - len(errors)) / len(step_df) * 100):.1f}%\")\n",
    "    \n",
    "    if len(errors) == 0:\n",
    "        print(\"🎉 すべて正解です！\")\n",
    "        return\n",
    "    \n",
    "    # 誤分類パターンの統計\n",
    "    print(f\"\\n📋 誤分類パターン:\")\n",
    "    error_patterns = errors.groupby([true_col, pred_col]).size().sort_values(ascending=False)\n",
    "    for (true_label, pred_label), count in error_patterns.items():\n",
    "        print(f\"  {true_label} → {pred_label}: {count} 件\")\n",
    "    \n",
    "    # 最大max_samples件の詳細表示\n",
    "    print(f\"\\n🔍 詳細分析 (最大{max_samples}件):\")\n",
    "    sample_errors = errors.head(max_samples)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_errors.iterrows(), 1):\n",
    "        print(f\"\\n--- 誤り {idx} ---\")\n",
    "        print(f\"画像: {Path(row['image_path']).name}\")\n",
    "        print(f\"正解: {row[true_col]}\")\n",
    "        print(f\"予測: {row[pred_col]}\")\n",
    "        print(f\"理由: {row[reasoning_col]}\")\n",
    "        \n",
    "        # 画像表示\n",
    "        title = f\"誤り{idx}: {row[true_col]} → {row[pred_col]}\"\n",
    "        display_image_from_url(row['image_url'], title)\n",
    "\n",
    "print(\"🔍 段階的分類誤り分析を開始します...\")\n",
    "\n",
    "# Step 1: OK/NG 分類誤り分析\n",
    "step1_true = valid_results_df['true_label'].apply(lambda x: 'OK' if x == 'OK' else 'NG')\n",
    "step1_df = valid_results_df.copy()\n",
    "step1_df['step1_true'] = step1_true\n",
    "\n",
    "analyze_step_errors(\n",
    "    step1_df, \n",
    "    \"Step 1 (OK/NG)\", \n",
    "    'step1_true', \n",
    "    'step_one_classification', \n",
    "    'step_one_reasoning'\n",
    ")\n",
    "\n",
    "# Step 2: 汚れ/加工不良 分類誤り分析（NGアイテムのみ）\n",
    "if len(ng_items) > 0:\n",
    "    step2_true = ng_items['true_label'].apply(lambda x: '汚れ' if x == '汚れ' else '加工不良')\n",
    "    step2_df = ng_items.copy()\n",
    "    step2_df['step2_true'] = step2_true\n",
    "    \n",
    "    analyze_step_errors(\n",
    "        step2_df,\n",
    "        \"Step 2 (汚れ/加工不良)\",\n",
    "        'step2_true',\n",
    "        'step_two_classification',\n",
    "        'step_two_reasoning'\n",
    "    )\n",
    "\n",
    "# Step 3: 欠け/削り節 分類誤り分析（加工不良アイテムのみ）\n",
    "if len(defect_items) > 0:\n",
    "    analyze_step_errors(\n",
    "        defect_items,\n",
    "        \"Step 3 (欠け/削り節)\",\n",
    "        'true_label',\n",
    "        'step_three_classification',\n",
    "        'step_three_reasoning'\n",
    "    )\n",
    "\n",
    "# 最終分類の全体誤り分析\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"📊 最終分類 全体誤り分析\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "final_errors = valid_results_df[valid_results_df['predicted'] != valid_results_df['true_label']]\n",
    "print(f\"📈 分析対象: {len(valid_results_df)} 件\")\n",
    "print(f\"❌ 最終誤分類: {len(final_errors)} 件\") \n",
    "print(f\"✅ 最終精度: {overall_accuracy:.3f}\")\n",
    "\n",
    "if len(final_errors) > 0:\n",
    "    print(f\"\\n📋 最終誤分類パターン:\")\n",
    "    final_error_patterns = final_errors.groupby(['true_label', 'predicted']).size().sort_values(ascending=False)\n",
    "    for (true_label, pred_label), count in final_error_patterns.items():\n",
    "        print(f\"  {true_label} → {pred_label}: {count} 件\")\n",
    "    \n",
    "    print(f\"\\n🔍 最終分類誤りの詳細 (最大5件):\")\n",
    "    sample_final_errors = final_errors.head(5)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_final_errors.iterrows(), 1):\n",
    "        print(f\"\\n--- 最終誤り {idx} ---\")\n",
    "        print(f\"画像: {Path(row['image_path']).name}\")\n",
    "        print(f\"正解: {row['true_label']}\")\n",
    "        print(f\"最終予測: {row['predicted']}\")\n",
    "        print(f\"Step1: {row['step_one_classification']} (確信度: {row['step_one_confidence']})\")\n",
    "        if row['step_two_classification']:\n",
    "            print(f\"Step2: {row['step_two_classification']} (確信度: {row['step_two_confidence']})\")\n",
    "        if row['step_three_classification']:\n",
    "            print(f\"Step3: {row['step_three_classification']} (確信度: {row['step_three_confidence']})\")\n",
    "        print(f\"全体確信度: {row['overall_confidence']:.1f}\")\n",
    "        \n",
    "        # 画像表示\n",
    "        title = f\"最終誤り{idx}: {row['true_label']} → {row['predicted']}\"\n",
    "        display_image_from_url(row['image_url'], title)\n",
    "\n",
    "print(\"\\n✅ 誤り分析が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 低確信度予測の分析 - 判定に迷いがある画像を特定\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_low_confidence_predictions(results_df, confidence_threshold=2, max_samples=5):\n",
    "    \"\"\"確信度が低い予測を分析\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🤔 低確信度予測分析 (確信度 ≤ {confidence_threshold})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 低確信度の予測を抽出\n",
    "    low_confidence = results_df[results_df['overall_confidence'] <= confidence_threshold]\n",
    "    \n",
    "    print(f\"📈 全体予測: {len(results_df)} 件\")\n",
    "    print(f\"⚠️ 低確信度: {len(low_confidence)} 件 ({len(low_confidence)/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(low_confidence) == 0:\n",
    "        print(\"✅ 低確信度の予測はありません\")\n",
    "        return\n",
    "    \n",
    "    # 確信度の統計\n",
    "    print(f\"\\n📊 確信度統計:\")\n",
    "    print(f\"平均確信度: {low_confidence['overall_confidence'].mean():.1f}\")\n",
    "    print(f\"最低確信度: {low_confidence['overall_confidence'].min():.1f}\")\n",
    "    print(f\"最高確信度: {low_confidence['overall_confidence'].max():.1f}\")\n",
    "    \n",
    "    # 正解/不正解の分布\n",
    "    correct_low_conf = low_confidence[low_confidence['predicted'] == low_confidence['true_label']]\n",
    "    incorrect_low_conf = low_confidence[low_confidence['predicted'] != low_confidence['true_label']]\n",
    "    \n",
    "    print(f\"\\n📋 低確信度予測の正解率:\")\n",
    "    print(f\"  正解: {len(correct_low_conf)} 件\")\n",
    "    print(f\"  不正解: {len(incorrect_low_conf)} 件\")\n",
    "    print(f\"  正解率: {len(correct_low_conf)/len(low_confidence)*100:.1f}%\")\n",
    "    \n",
    "    # カテゴリ別の低確信度分布\n",
    "    print(f\"\\n📈 カテゴリ別低確信度分布:\")\n",
    "    category_dist = low_confidence['true_label'].value_counts()\n",
    "    for category, count in category_dist.items():\n",
    "        print(f\"  {category}: {count} 件\")\n",
    "    \n",
    "    # 最も確信度の低い予測を表示\n",
    "    print(f\"\\n🔍 最も確信度の低い予測 (最大{max_samples}件):\")\n",
    "    lowest_conf = low_confidence.nsmallest(max_samples, 'overall_confidence')\n",
    "    \n",
    "    for idx, (_, row) in enumerate(lowest_conf.iterrows(), 1):\n",
    "        print(f\"\\n--- 低確信度 {idx} (確信度: {row['overall_confidence']:.1f}) ---\")\n",
    "        print(f\"画像: {Path(row['image_path']).name}\")\n",
    "        print(f\"正解: {row['true_label']}\")\n",
    "        print(f\"予測: {row['predicted']} {'✅' if row['predicted'] == row['true_label'] else '❌'}\")\n",
    "        print(f\"Step1: {row['step_one_classification']} (確信度: {row['step_one_confidence']})\")\n",
    "        if row['step_two_classification']:\n",
    "            print(f\"Step2: {row['step_two_classification']} (確信度: {row['step_two_confidence']})\")\n",
    "        if row['step_three_classification']:\n",
    "            print(f\"Step3: {row['step_three_classification']} (確信度: {row['step_three_confidence']})\")\n",
    "        \n",
    "        # 画像表示\n",
    "        title = f\"低確信度{idx}: {row['true_label']} → {row['predicted']} (確信度: {row['overall_confidence']:.1f})\"\n",
    "        display_image_from_url(row['image_url'], title)\n",
    "\n",
    "# 低確信度予測の分析実行\n",
    "analyze_low_confidence_predictions(valid_results_df, confidence_threshold=2, max_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa46be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ステップ間予測変化分析 - 段階的分類でどのように判定が変わったかを追跡\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_prediction_flow(results_df, max_samples=3):\n",
    "    \"\"\"段階的分類の予測フローを分析\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🔄 段階的分類フロー分析\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Step1でOKと判定されたもの\n",
    "    ok_predictions = results_df[results_df['step_one_classification'] == 'OK']\n",
    "    print(f\"📊 Step1でOK判定: {len(ok_predictions)} 件\")\n",
    "    \n",
    "    # Step1でOKだが実際はNGのもの（誤判定）\n",
    "    ok_but_ng = ok_predictions[ok_predictions['true_label'] != 'OK']\n",
    "    if len(ok_but_ng) > 0:\n",
    "        print(f\"❌ Step1でOK誤判定: {len(ok_but_ng)} 件\")\n",
    "        print(\"詳細:\")\n",
    "        for label in ['汚れ', '欠け', '削り節']:\n",
    "            count = len(ok_but_ng[ok_but_ng['true_label'] == label])\n",
    "            if count > 0:\n",
    "                print(f\"  {label}をOKと誤判定: {count} 件\")\n",
    "        \n",
    "        # サンプル表示\n",
    "        print(f\"\\n🔍 Step1 OK誤判定サンプル (最大{max_samples}件):\")\n",
    "        for idx, (_, row) in enumerate(ok_but_ng.head(max_samples).iterrows(), 1):\n",
    "            print(f\"\\n--- OK誤判定 {idx} ---\")\n",
    "            print(f\"画像: {Path(row['image_path']).name}\")\n",
    "            print(f\"正解: {row['true_label']} → Step1予測: OK\")\n",
    "            print(f\"Step1理由: {row['step_one_reasoning']}\")\n",
    "            print(f\"Step1確信度: {row['step_one_confidence']}\")\n",
    "            \n",
    "            title = f\"OK誤判定{idx}: {row['true_label']} → OK\"\n",
    "            display_image_from_url(row['image_url'], title)\n",
    "    \n",
    "    # Step2の分析\n",
    "    ng_predictions = results_df[results_df['step_one_classification'] == 'NG']\n",
    "    if len(ng_predictions) > 0:\n",
    "        print(f\"\\n📊 Step1でNG判定: {len(ng_predictions)} 件\")\n",
    "        \n",
    "        # Step2で汚れと判定されたもの\n",
    "        dirt_predictions = ng_predictions[ng_predictions['step_two_classification'] == '汚れ']\n",
    "        print(f\"  Step2で汚れ判定: {len(dirt_predictions)} 件\")\n",
    "        \n",
    "        # Step2で汚れだが実際は加工不良のもの\n",
    "        dirt_but_defect = dirt_predictions[dirt_predictions['true_label'].isin(['欠け', '削り節'])]\n",
    "        if len(dirt_but_defect) > 0:\n",
    "            print(f\"  ❌ Step2で汚れ誤判定: {len(dirt_but_defect)} 件\")\n",
    "            \n",
    "            print(f\"\\n🔍 Step2 汚れ誤判定サンプル (最大{max_samples}件):\")\n",
    "            for idx, (_, row) in enumerate(dirt_but_defect.head(max_samples).iterrows(), 1):\n",
    "                print(f\"\\n--- 汚れ誤判定 {idx} ---\")\n",
    "                print(f\"画像: {Path(row['image_path']).name}\")\n",
    "                print(f\"正解: {row['true_label']} → Step2予測: 汚れ\")\n",
    "                print(f\"Step2理由: {row['step_two_reasoning']}\")\n",
    "                print(f\"Step2確信度: {row['step_two_confidence']}\")\n",
    "                \n",
    "                title = f\"汚れ誤判定{idx}: {row['true_label']} → 汚れ\"\n",
    "                display_image_from_url(row['image_url'], title)\n",
    "        \n",
    "        # Step3の分析\n",
    "        defect_predictions = ng_predictions[ng_predictions['step_two_classification'] == '加工不良']\n",
    "        if len(defect_predictions) > 0:\n",
    "            print(f\"\\n📊 Step2で加工不良判定: {len(defect_predictions)} 件\")\n",
    "            \n",
    "            # Step3での欠け/削り節の判定誤り\n",
    "            step3_errors = defect_predictions[defect_predictions['step_three_classification'] != defect_predictions['true_label']]\n",
    "            if len(step3_errors) > 0:\n",
    "                print(f\"  ❌ Step3で誤判定: {len(step3_errors)} 件\")\n",
    "                \n",
    "                print(f\"\\n🔍 Step3 誤判定サンプル (最大{max_samples}件):\")\n",
    "                for idx, (_, row) in enumerate(step3_errors.head(max_samples).iterrows(), 1):\n",
    "                    print(f\"\\n--- Step3誤判定 {idx} ---\")\n",
    "                    print(f\"画像: {Path(row['image_path']).name}\")\n",
    "                    print(f\"正解: {row['true_label']} → Step3予測: {row['step_three_classification']}\")\n",
    "                    print(f\"Step3理由: {row['step_three_reasoning']}\")\n",
    "                    print(f\"Step3確信度: {row['step_three_confidence']}\")\n",
    "                    \n",
    "                    title = f\"Step3誤判定{idx}: {row['true_label']} → {row['step_three_classification']}\"\n",
    "                    display_image_from_url(row['image_url'], title)\n",
    "\n",
    "# 段階的分類フロー分析の実行\n",
    "analyze_prediction_flow(valid_results_df, max_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b036c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 段階的分類サマリーレポート\n",
    "# =============================================================================\n",
    "\n",
    "def generate_summary_report(results_df):\n",
    "    \"\"\"段階的分類の包括的なサマリーレポートを生成\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"📊 段階的二値分類 包括サマリーレポート\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    total_images = len(results_df)\n",
    "    valid_images = len(results_df[results_df['predicted'] != 'ERROR'])\n",
    "    \n",
    "    print(f\"🔢 基本統計:\")\n",
    "    print(f\"  総画像数: {total_images}\")\n",
    "    print(f\"  有効分類: {valid_images} ({valid_images/total_images*100:.1f}%)\")\n",
    "    print(f\"  最終精度: {overall_accuracy:.3f}\")\n",
    "    \n",
    "    # 各ステップの精度\n",
    "    step1_true = valid_results_df['true_label'].apply(lambda x: 'OK' if x == 'OK' else 'NG')\n",
    "    step1_accuracy = (step1_true == valid_results_df['step_one_classification']).mean()\n",
    "    \n",
    "    print(f\"\\n📈 ステップ別精度:\")\n",
    "    print(f\"  Step 1 (OK/NG): {step1_accuracy:.3f}\")\n",
    "    \n",
    "    if len(ng_items) > 0:\n",
    "        step2_true = ng_items['true_label'].apply(lambda x: '汚れ' if x == '汚れ' else '加工不良')\n",
    "        step2_accuracy = (step2_true == ng_items['step_two_classification']).mean()\n",
    "        print(f\"  Step 2 (汚れ/加工不良): {step2_accuracy:.3f}\")\n",
    "    \n",
    "    if len(defect_items) > 0:\n",
    "        step3_accuracy = (defect_items['true_label'] == defect_items['step_three_classification']).mean()\n",
    "        print(f\"  Step 3 (欠け/削り節): {step3_accuracy:.3f}\")\n",
    "    \n",
    "    # 確信度統計\n",
    "    print(f\"\\n🎯 確信度統計:\")\n",
    "    print(f\"  全体確信度平均: {valid_results_df['overall_confidence'].mean():.1f}\")\n",
    "    print(f\"  Step1確信度平均: {valid_results_df['step_one_confidence'].mean():.1f}\")\n",
    "    if len(ng_items) > 0:\n",
    "        print(f\"  Step2確信度平均: {ng_items['step_two_confidence'].mean():.1f}\")\n",
    "    if len(defect_items) > 0:\n",
    "        print(f\"  Step3確信度平均: {defect_items['step_three_confidence'].mean():.1f}\")\n",
    "    \n",
    "    # カテゴリ別分析\n",
    "    print(f\"\\n📊 カテゴリ別性能:\")\n",
    "    for label in ['OK', '汚れ', '欠け', '削り節']:\n",
    "        true_count = len(valid_results_df[valid_results_df['true_label'] == label])\n",
    "        correct_count = len(valid_results_df[\n",
    "            (valid_results_df['true_label'] == label) & \n",
    "            (valid_results_df['predicted'] == label)\n",
    "        ])\n",
    "        if true_count > 0:\n",
    "            accuracy = correct_count / true_count\n",
    "            print(f\"  {label}: {correct_count}/{true_count} ({accuracy:.3f})\")\n",
    "    \n",
    "    # 主要な問題点\n",
    "    print(f\"\\n⚠️ 主要な問題点:\")\n",
    "    \n",
    "    # Step1でOKと誤判定\n",
    "    ok_errors = valid_results_df[\n",
    "        (valid_results_df['step_one_classification'] == 'OK') & \n",
    "        (valid_results_df['true_label'] != 'OK')\n",
    "    ]\n",
    "    if len(ok_errors) > 0:\n",
    "        print(f\"  • 不良品をOKと誤判定: {len(ok_errors)} 件\")\n",
    "    \n",
    "    # Step2で汚れと誤判定\n",
    "    dirt_errors = ng_items[\n",
    "        (ng_items['step_two_classification'] == '汚れ') & \n",
    "        (ng_items['true_label'].isin(['欠け', '削り節']))\n",
    "    ] if len(ng_items) > 0 else pd.DataFrame()\n",
    "    if len(dirt_errors) > 0:\n",
    "        print(f\"  • 加工不良を汚れと誤判定: {len(dirt_errors)} 件\")\n",
    "    \n",
    "    # 低確信度予測\n",
    "    low_conf = valid_results_df[valid_results_df['overall_confidence'] <= 5]\n",
    "    if len(low_conf) > 0:\n",
    "        print(f\"  • 低確信度予測 (≤5): {len(low_conf)} 件 ({len(low_conf)/len(valid_results_df)*100:.1f}%)\")\n",
    "    \n",
    "    # 改善提案\n",
    "    print(f\"\\n💡 改善提案:\")\n",
    "    \n",
    "    if len(ok_errors) > 5:\n",
    "        print(f\"  • Step1のNG検出感度向上が必要\")\n",
    "        print(f\"    - より多様なNG例をサンプルに追加\")\n",
    "        print(f\"    - プロンプトでの異常検出基準を強化\")\n",
    "    \n",
    "    if len(dirt_errors) > 3:\n",
    "        print(f\"  • Step2の汚れ/加工不良判別精度向上が必要\")\n",
    "        print(f\"    - 汚れと物理的損傷の特徴差を明確化\")\n",
    "        print(f\"    - より具体的な判定基準を提供\")\n",
    "    \n",
    "    if len(low_conf) > len(valid_results_df) * 0.1:\n",
    "        print(f\"  • 確信度向上が必要\")\n",
    "        print(f\"    - サンプル数の増加\")\n",
    "        print(f\"    - より明確な判定基準の設定\")\n",
    "    \n",
    "    print(f\"\\n✅ レポート生成完了\")\n",
    "\n",
    "# サマリーレポートの生成\n",
    "generate_summary_report(valid_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c07894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1dca99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc04be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
